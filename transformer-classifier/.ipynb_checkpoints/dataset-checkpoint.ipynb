{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# vectorize sequences as inputs \n",
    "def seq_to_tensor(raw_sample,dim_model=728):\n",
    "    seq_embed = torch.tensor([np.concatenate([word_embedding[word2idx[w]],pos_embedding[pos2idx[raw_sample[\"pos\"][i]]]]) \n",
    "                       for i,w in enumerate(raw_sample[\"word\"])])\n",
    "    return seq_embed\n",
    "    \n",
    "# dynamic padding: seqeuences are padded to the maximum length of mini-batch sequences\n",
    "def collate_fn(batch):\n",
    "    sorted_batch = sorted(batch, key=lambda x: x[0].size(0), reverse=True)\n",
    "    sequences = [x[0] for x in sorted_batch]\n",
    "    sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "    lengths = torch.LongTensor([len(x) for x in sequences])\n",
    "    labels = torch.LongTensor(list(map(lambda x: x[1], sorted_batch)))\n",
    "    feats = torch.FloatTensor(list(map(lambda x: x[2], sorted_batch)))\n",
    "    return sequences_padded, labels, lengths, feats\n",
    "\n",
    "class IronyDataset(Dataset):\n",
    "    def __init__(self, raw_data, transform=None, addition_feats=None, with_label=True):\n",
    "        self.data = raw_data\n",
    "        self.transform = transform\n",
    "        self.addition_feats = addition_feats\n",
    "        self.with_label = with_label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        label = []\n",
    "        feats = []\n",
    "        if self.with_label:\n",
    "            label = self.data[index][\"label\"]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        if self.addition_feats is not None:\n",
    "            feats = self.addition_feats[index]\n",
    "            \n",
    "        return sample, label, feats"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
